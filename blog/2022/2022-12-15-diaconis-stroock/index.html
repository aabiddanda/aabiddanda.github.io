<!doctype html>
<html class="no-js" lang="en" data-content_root="../../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../../genindex/" /><link rel="search" title="Search" href="../../../search/" />

    <link rel="shortcut icon" href="../../../_static/favicon.ico"/><!-- Generated with Sphinx 7.4.7 and Furo 2025.07.19 -->
        <title>Diaconis-Stroock Eigenvalue Bounds for Markov Chain Convergence - Arjun Biddanda</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?v=25af2a20" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/override.css?v=e89897b8" />
    <link rel="stylesheet" type="text/css" href="https://use.typekit.net/ajj5weq.css" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  --font-stack: acumin-pro, sans-serif;
  --color-background-primary: #f8f8f8;
  --color-background-secondary: #f8f8f8;
  --color-background-hover: #F5F3ED;
  --color-brand-primary: black;
  --color-brand-content: #A46F0D;
  --admonition-font-size: var(--font-size-normal);
  --admonition-title-font-size: var(--font-size-normal);
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../"><div class="brand">Arjun Biddanda</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><div class="sidebar-scroll"><a class="sidebar-brand" href="../../../">
  
  <span class="sidebar-brand-text">Arjun Biddanda</span>
  
</a><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../research/">Research</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cv/">Curriculum Vitae</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../publications/">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../software/">Software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../">Blog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/">Notes &amp; Miscellanea</a></li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../../../_sources/blog/2022/2022-12-15-diaconis-stroock.md.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section class="tex2jax_ignore mathjax_ignore" id="diaconis-stroock-eigenvalue-bounds-for-markov-chain-convergence">
<h1>Diaconis-Stroock Eigenvalue Bounds for Markov Chain Convergence<a class="headerlink" href="#diaconis-stroock-eigenvalue-bounds-for-markov-chain-convergence" title="Link to this heading">¶</a></h1>
<!-- tags: [eigenvalues, markov chains, graph theory] -->
<section id="markov-chains">
<h2>Markov Chains<a class="headerlink" href="#markov-chains" title="Link to this heading">¶</a></h2>
<p>Markov Chains are a fundamental stochastic processes that are used in a wide variety of fields. They can be represented by state machines where the probability of moving between the states are “transition” probabilities. Markov Chains follow the <a class="reference external" href="https://en.wikipedia.org/wiki/Markov_property">Markov Property</a>, and below we provide a depiction of a Markov Chain as a graph.</p>
<a class="reference internal image-reference" href="../../../_images/markov_chain_demo.png"><img alt="../../../_images/markov_chain_demo.png" class="align-center" src="../../../_images/markov_chain_demo.png" style="width: 500px; height: 350px;" />
</a>
<center>A simple Markov Chain </center>
<br>
<p>For the Markov Chain above, we can create a matrix out of the transition probabilities that we move from a starting state to any other state as the following matrix:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{P} =\begin{bmatrix}
0.42 &amp; 0.25 &amp; 0.33\\
0.25 &amp; 0.42 &amp; 0.33\\
0.33 &amp; 0.33 &amp; 0.33\\
\end{bmatrix}
\end{split}\]</div>
</div>
<p>Now a natural question to ask is whether if we let this state machine play out over infinite time, would it reach some sort of equilibrium? This equilibrium on the states is the <em>stationary distribution</em> of the markov chain.</p>
<p>The stationary distribution can be described by a distribution on the states, <span class="math notranslate nohighlight">\(\mathbf{\pi}\)</span>, a column vector that obeys the following equality:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[ \mathbf{\pi}^T = \mathbf{\pi}^T\mathbf{P} \]</div>
</div>
<p>How might we approach finding this stationary distribution though? There are three ways we might try: (1) take the transition matrix <span class="math notranslate nohighlight">\(P\)</span> to a very high power and extract a row, (2) solve via a set of global-balance equations, or (3) solve for the stationary distribution via eigen-decomposition. The first approach is quite unprincipled (because defining the power seems difficult), and the second approach is explained <a class="reference external" href="http://stephens999.github.io/fiveMinuteStats/analysis/stationary_distribution.html">here</a>, so we will go with the eigen-decomposition.</p>
<p>We can describe the eigen-decomposition as the following equation:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[ xA = \lambda x \]</div>
</div>
<p>Where <span class="math notranslate nohighlight">\(A\)</span> are all of the left-eigenvectors, and <span class="math notranslate nohighlight">\(\lambda\)</span> are all of the eigenvalues. If <span class="math notranslate nohighlight">\(\lambda = 1\)</span> then we would exactly have the equation for the stationary distribution. In fact, there is a nice property about the ordering about the eigenvalues of <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> in that:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[ 1 = \lambda_0 &gt; \lambda_1 \geq ... \geq \lambda_{m-1} \geq -1, \hspace{4pt} m = |\mathbf{P}|\]</div>
</div>
<p>From all of the above we have a principled way to compute the stationary distribution of an arbitrary markov chain, supposing that we can calculate an eigen-decomposition of the transition probability matrix.<a class="footnote-reference brackets" href="#id4" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p>
<p>It is nice that this stationary distribution is solvable, but we can also ask <em>how fast</em> the approach to the stationary distribution is. This is related to the difference between the first and second eigenvalues in the eigen-decomposition or <span class="math notranslate nohighlight">\(| 1 - \lambda_1 |\)</span>. The general idea is that <span class="math notranslate nohighlight">\(\lambda_1\)</span> tells us how fast the largest of the vanishing terms (<span class="math notranslate nohighlight">\(\lambda_i &lt; 1\)</span>) approach 0 and disappear.</p>
<p>Here we go over some theory and methods that pertain to random walks on graphs (and subsequently Markov Chains) to determine bounds on the value of the second eigenvalue <span class="math notranslate nohighlight">\(\lambda_1\)</span> and providing a bound on the convergence of Markov chains to their stationary distributions.</p>
</section>
<section id="eigenvalue-bounds-via-poincare-inequalities">
<h2>Eigenvalue Bounds via Poincare Inequalities<a class="headerlink" href="#eigenvalue-bounds-via-poincare-inequalities" title="Link to this heading">¶</a></h2>
<p>To start we need to actually define the graph, where there is an edge on <span class="math notranslate nohighlight">\(\{x,y\}\)</span> if <span class="math notranslate nohighlight">\(Q(x,y) &gt; 0\)</span>, where <span class="math notranslate nohighlight">\(Q(x,y) = \pi(x)P(x,y)\)</span>. This means that an edge should exist if there is any probability of moving from state <span class="math notranslate nohighlight">\(x\)</span> to state <span class="math notranslate nohighlight">\(y\)</span>. We can then define path lengths through the graph from node <span class="math notranslate nohighlight">\(x\)</span> to node <span class="math notranslate nohighlight">\(y\)</span> as :</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[ |\gamma_{xy}|  = \sum_{e \in \gamma_{xy}} \frac{1}{Q(e)} \]</div>
</div>
<p>, where <span class="math notranslate nohighlight">\(Q(e) = Q(x,y)\)</span> if <span class="math notranslate nohighlight">\(e = {x,y}\)</span> as a shorthand notation. Assuming the Markov Chain is <a class="reference external" href="https://en.wikipedia.org/wiki/Markov_chain#Properties">irreducible</a>, we know that paths exist from every state to every other state in the Markov Chain.</p>
<p>From this notion of paths through the graph, a further definition can be made:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\kappa = \text{max}_e \sum_{e \ni \gamma_{xy}} |\gamma_{xy}|\pi(x)\pi(y)\]</div>
</div>
<p>, where the maximum is taken over all directed edges in the graph, and is summed over all paths that contain that maximal edge. This quantity can intuitively be thought of as finding the largest “bottleneck” in the flow of probability between the states of the Markov Chain that go through the directed edge <span class="math notranslate nohighlight">\(e\)</span>. This is related to ideas about <a class="reference external" href="https://en.wikipedia.org/wiki/Max-flow_min-cut_theorem">max-flow/min-cut</a> and the <a class="reference external" href="https://en.wikipedia.org/wiki/Ford%E2%80%93Fulkerson_algorithm">Ford-Fulkerson algorithm</a>.</p>
<section id="derivation-of-poincare-bounds">
<h3>Derivation of Poincare Bounds<a class="headerlink" href="#derivation-of-poincare-bounds" title="Link to this heading">¶</a></h3>
<p>If we define <span class="math notranslate nohighlight">\(\phi (x)\)</span> as a continuous function on the finite states of the Markov Chains <span class="math notranslate nohighlight">\(x \in X\)</span>, we can explore the convergence of the Markov-Chain while accounting for a specific “value” or “weight” for each of the states.</p>
<p>In order to prove our upper-bound on the eigenvalue of <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> we need to work with the <a class="reference external" href="https://en.wikipedia.org/wiki/Laplacian_matrix">Laplacian</a> of <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> which is defined as:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[ \mathbf{L} = \mathbf{I} - \mathbf{P}, \beta_i = 1 - \lambda_i\]</div>
</div>
<p>Where <span class="math notranslate nohighlight">\(\beta_i\)</span> are the eigenvalues of <span class="math notranslate nohighlight">\(\mathbf{L}\)</span>. Following from previous work (<a class="reference external" href="https://www.google.com/books/edition/Matrix_Analysis/PlYQN0ypTwEC?hl=en">Horn and Johnson</a>), we can define the following:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[ \beta_1 = inf\left\{ \frac{E(\phi, \phi)}{Var(\phi)} \right\} \]</div>
</div>
<p>Where <span class="math notranslate nohighlight">\(Var(\phi)\)</span> is the variance of <span class="math notranslate nohighlight">\(\phi\)</span> relative to <span class="math notranslate nohighlight">\(\pi\)</span> and</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[ E(\phi, \phi) = \frac{1}{2} \sum_{x,y} (\phi(x) - \phi(y))^2Q(x,y)\]</div>
</div>
<p>From the definitions of <span class="math notranslate nohighlight">\(Var(\phi)\)</span> and <span class="math notranslate nohighlight">\(\kappa\)</span>  we can start our derivation:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
	Var(\phi) &amp;= \frac{1}{2} \sum_{x,y \in X} (\phi(x) - \phi(y))^2\pi(x)\pi(y)\\
	&amp;\leq \frac{1}{2} \sum_{x,y \in X} |\gamma_{xy}|\pi(x)\pi(y) \sum_{\gamma_{xy} \ni e} Q(e)\phi(e)^2\\
	&amp;= \frac{1}{2} \sum_{e} \phi(e)^2 Q(e) \sum_{\gamma_{x,y} \ni e } |\gamma_{xy}| \pi(x)\pi(y)\\
	&amp;= E(\phi, \phi) \sum_{\gamma_{x,y} \ni e } |\gamma_{xy}| \pi(x)\pi(y)\\
	Var(\phi) &amp;\leq \kappa E(\phi, \phi)\\
	\beta_1 &amp;= inf \left\{ \frac{E(\phi, \phi)}{Var(\phi)} \right\}\\
	&amp;\geq \frac{E(\phi, \phi)}{\kappa E(\phi, \phi)}\\
	&amp;\geq \frac{1}{\kappa}\\
	\lambda_1 &amp;\leq 1 - \beta_1\\
	\lambda_1 &amp;\leq 1 - \frac{1}{\kappa}
\end{aligned}
\end{split}\]</div>
</div>
<p>Note that while the results above are elegant from a mathematical perspective, for actual practicality this is a little bit tricky since the quantity <span class="math notranslate nohighlight">\(\kappa\)</span> contains terms related to the stationary distribution! However we can bound <span class="math notranslate nohighlight">\(\kappa\)</span> in terms of structural elements of the Markov Chain graph thereby reducing our reliance on knowing the stationary distribution.</p>
</section>
</section>
<section id="eigenvalue-bounds-via-graph-structure">
<h2>Eigenvalue Bounds via Graph Structure<a class="headerlink" href="#eigenvalue-bounds-via-graph-structure" title="Link to this heading">¶</a></h2>
<p>To characterize the effect of graph structure on the eigenvalue bounds, we first define the properties of the graph <span class="math notranslate nohighlight">\(G = (V,E)\)</span> and a random walk from a node to any of its neighbors being only dependent on the degree of the node:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split} P(x,y) = \begin{cases}
      \frac{1}{d(x)} &amp; (x,y) \in E \\
      0 &amp; else\\
   \end{cases} \end{split}\]</div>
</div>
<p>Due to this uniformity in choosing the next node, the stationary distribution of visiting a node <span class="math notranslate nohighlight">\(x\)</span> is the node’s degree over the total number of edges in the graph <span class="math notranslate nohighlight">\(\pi(x) = \frac{d(x)}{2\|E\|} \)</span> <a class="footnote-reference brackets" href="#id5" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>.</p>
<p>From there we can define:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split} Q(x,y) = \begin{cases}
      \frac{1}{2|E|} &amp; (x,y) \in E \\
      0 &amp; else\\
   \end{cases} \end{split}\]</div>
</div>
<p>We can then adequately bound <span class="math notranslate nohighlight">\(\kappa\)</span> just by properties of the random walk:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
	| \gamma_{xy} |  &amp;= \sum_{e \in \gamma_{xy}} \frac{1}{Q(e)}\\
	&amp;\leq 2|E|\gamma_* b\\
	\gamma_* &amp;= max_\gamma |\gamma|\\
	b &amp;= max_e {\gamma \in \Gamma, e \in \gamma}\\
	\kappa &amp;= \text{max}_e \sum_{e \in \gamma_{xy}} |\gamma_{xy}|\pi(x)\pi(y)\\
	&amp;\leq max_e \sum_{e \in \gamma_{xy}} |\gamma_{xy}| \left(\frac{d_*}{2|E|}\right)^2\\
	&amp;\leq \left(\frac{d_*}{2|E|}\right)^2 2|E|\gamma_* b\\
	&amp;= \frac{bd_*^2\gamma_*}{2|E|}\\
\end{aligned}
\end{split}\]</div>
</div>
<p>The term <span class="math notranslate nohighlight">\(b\)</span> describes the maximum number of paths that pass through the edge, a measure of which edge bottlenecks the graph. The term <span class="math notranslate nohighlight">\( \gamma_* \)</span> simply describes the longest path within the graph (in numbers of edges). <span class="math notranslate nohighlight">\( d_* \)</span> is the maximal degree of any node within the graph.</p>
<p>From our redefining the upper bound on <span class="math notranslate nohighlight">\(\kappa\)</span> we can turn to our redefinition of the first eigenvalue:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
	\kappa &amp;\leq \frac{bd_*^2\gamma_*}{2|E|}\\
	\lambda_1 &amp;\leq 1 - \frac{1}{\kappa}\\
	&amp;\leq 1 - \frac{2|E|}{bd_*^2\gamma_*}
\end{aligned}
\end{split}\]</div>
</div>
<p>While the random-walk assumption may not be appropriate for all scenarios, it certainly holds in a large number of them and that is what makes this bound of use in practical scenarios. It also suggests that algorithmic methods to reduce any element of the denominator will result in faster mixing of the Markov-Chain towards stationarity. In principle, one approach is to artifically reduce the prevalence of “hubs” in the network to decrease the maximal degree of a node within the graph <span class="math notranslate nohighlight">\( d_* \)</span> since that value affects the bound with <span class="math notranslate nohighlight">\(\mathcal{O}(d_*^{-2})\)</span>.</p>
<p>As an experiment, you can see what the effect of different simulated graph structures are on the second eigenvalue bound <span class="math notranslate nohighlight">\(\lambda_1\)</span>. Provided a given graph <span class="math notranslate nohighlight">\(G\)</span>, we can calculate the bounds as mentioned above to check for how close we can get to stationarity. From the brief experiment it appears that graphs where edges are placed according to a uniform probability have a slightly faster mixing rate than “small-world” networks that are randomly generated. For the full notebook details of the specifics of the experiment please see this <a class="reference external" href="https://gist.github.com/aabiddanda/643d71ae881bcb7bd51a53d396286846">gist</a>.</p>
<a class="reference internal image-reference" href="../../../_images/eigenvalue_bounds.01082022.png"><img alt="../../../_images/eigenvalue_bounds.01082022.png" class="align-center" src="../../../_images/eigenvalue_bounds.01082022.png" style="width: 600px; height: 350px;" />
</a>
<center>The impact of different graph structures across 100 random graphs</center>
<br>
</section>
<section id="implications">
<h2>Implications<a class="headerlink" href="#implications" title="Link to this heading">¶</a></h2>
<p>I first learned about these ideas on rates of Markov Chain convergence in the context of two very different models. The first was determining properties of genealogies when there is a specific form of population structure known as the “island model”. The island model is a population dynamic model where the migration matrix between a set of demes is fully-connected and has weights (migration rates) that are non-zero. However, the migration rates may be different by orders of magnitude, creating scenarios where different collections of “islands” or demes are more well connected.</p>
<p>The upper bound on the second eigenvalue of a random-walk in an <span class="math notranslate nohighlight">\(n\)</span>-deme island model derived by <a class="reference external" href="https://wakeleylab.oeb.harvard.edu/publications/convergence-island-model-coalescent-process-populations-restricted-migration">Matsen and Wakeley</a> is:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\kappa &amp;\leq \frac{b\gamma_*d_*}{n}\\
\lambda_1 &amp;\leq 1 - \frac{1}{\kappa}\\
&amp;\leq  1 - \frac{n}{b\gamma_*d_*}\\
\end{aligned}
\end{split}\]</div>
</div>
<p>Thus we can use the bounds proposed here to compute the upper bound on the convergence to the island model even if there is limited migration (e.g. where some components of the island model are well-connected but limited connectivity between components). Notably, Matsen and Wakeley use this bound to show that there is no dependence on the number of samples, but rather this can be used to show properties of the genealogies when there is an infinite number of demes (<span class="math notranslate nohighlight">\(n \rightarrow \infty\)</span> in our notation).</p>
<p>The second context was in Markov Chain Monte Carlo (MCMC) sampling distributions that have multiple modes. The primary problem with running a Markov Chain to sample from a multi-modal distribution is that if it gets “stuck” in a mode, it can be difficult to sample outside of the mode because the most likely proposal is to stay within that specific mode of the stationary distribution. In the graph-theoretic sense, it would be like having many small but dense sub-networks and there are very few connections between these small, dense networks so it is very difficult to randomly move between sub-networks. If we review the expression for the eigenvalue bounds that we saw before based on the graph structure we have:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[ \lambda_1 \leq 1 - \frac{2|E|}{bd_*^2\gamma_*} \]</div>
</div>
<p>These small-world networks have high node density (which increases the maximum degree of the node- <span class="math notranslate nohighlight">\( d_* \)</span>) as well as it being quite difficult to travel between them (increasing the maximum path length - <span class="math notranslate nohighlight">\( \gamma_* \)</span>). These two properties, particularly the increase of the maximum degree, really hurts the rate of convergence to the stationary distribution. To address this problem, one can leverage MCMC algorithms where one runs multiple MCMC chains with different levels of “heat”<a class="footnote-reference brackets" href="#id6" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>. One can also ideally leverage the eigenvalue bounds to set a data-driven establishment of where to set the number of burn-in iterations for MCMC.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://projecteuclid.org/journals/annals-of-applied-probability/volume-1/issue-1/Geometric-Bounds-for-Eigenvalues-of-Markov-Chains/10.1214/aoap/1177005980.full">Diaconis and Stroock 1991</a></p></li>
<li><p><a class="reference external" href="https://wakeleylab.oeb.harvard.edu/sites/hwpi.harvard.edu/files/wakeleylab/files/matsenandwakeley06.pdf?m=1442935676">Matsen and Wakeley 2006</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/math/0703021">Guan &amp; Krone 2007</a></p></li>
</ul>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id4" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>In practice most algorithms scale at rates <span class="math notranslate nohighlight">\(\mathcal{O}(n^\omega)\)</span>, where <span class="math notranslate nohighlight">\(2 &lt; \omega \leq 3\)</span>. Even with an iterative algorithm, one would need to perform at least 2 iterations (which run quadratically in the number of matrix entries). For more information on this see this <a class="reference external" href="http://comet.lehman.cuny.edu/vpan/pdf/165.pdf">paper</a></p>
</aside>
<aside class="footnote brackets" id="id5" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Note that here I am assuming that the graph is undirected and contains no cycles.</p>
</aside>
<aside class="footnote brackets" id="id6" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>“heating” or “tempering” is a technique where you can increase the variance of the proposals to suggest larger jumps (they have a flatter likelihood surface). for more details see <a class="reference external" href="https://en.wikipedia.org/wiki/Parallel_tempering">here</a></p>
</aside>
</aside>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, Arjun Biddanda
            </div>
            Made with 
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/aabiddanda/" aria-label="GitHub">
            <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
            </svg>
        </a>
              <a class="muted-link " href="https://bsky.app/profile/aabiddanda.bsky.social/" aria-label="Bluesky">
            <svg xmlns="http://www.w3.org/2000/svg" stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z"/></svg>
            </svg>
        </a>
              <a class="muted-link " href="https://scholar.google.com/citations?user=BWVZXhgAAAAJ&hl=en" aria-label="Google Scholar">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d="M390.9 298.5c0 0 0 .1 .1 .1c9.2 19.4 14.4 41.1 14.4 64C405.3 445.1 338.5 512 256 512s-149.3-66.9-149.3-149.3c0-22.9 5.2-44.6 14.4-64h0c1.7-3.6 3.6-7.2 5.6-10.7c4.4-7.6 9.4-14.7 15-21.3c27.4-32.6 68.5-53.3 114.4-53.3c33.6 0 64.6 11.1 89.6 29.9c9.1 6.9 17.4 14.7 24.8 23.5c5.6 6.6 10.6 13.8 15 21.3c2 3.4 3.8 7 5.5 10.5zm26.4-18.8c-30.1-58.4-91-98.4-161.3-98.4s-131.2 40-161.3 98.4L0 202.7 256 0 512 202.7l-94.7 77.1z"/></svg>
        </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Diaconis-Stroock Eigenvalue Bounds for Markov Chain Convergence</a><ul>
<li><a class="reference internal" href="#markov-chains">Markov Chains</a></li>
<li><a class="reference internal" href="#eigenvalue-bounds-via-poincare-inequalities">Eigenvalue Bounds via Poincare Inequalities</a><ul>
<li><a class="reference internal" href="#derivation-of-poincare-bounds">Derivation of Poincare Bounds</a></li>
</ul>
</li>
<li><a class="reference internal" href="#eigenvalue-bounds-via-graph-structure">Eigenvalue Bounds via Graph Structure</a></li>
<li><a class="reference internal" href="#implications">Implications</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../../_static/documentation_options.js?v=d4c685ee"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/tabs.js?v=3ee01567"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://www.googletagmanager.com/gtag/js?id=G-ZXEQFEKF68"></script>
    <script src="../../../_static/google_analytics_tracker.js?v=c15d0c3e"></script>
    </body>
</html>